{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "(2,2)b_(1)_(1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sa21262/datascience22/blob/main/Dissertation_codes/(2%2C2)b_(1)_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Required Libraries  "
      ],
      "metadata": {
        "id": "CW8m7EYH-NH6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpECXu6zYkIF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.layers import Input, Dense, GaussianNoise,Lambda,Dropout, Concatenate\n",
        "from keras.models import Model\n",
        "from keras import regularizers\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras import backend as K\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import load_model\n",
        "from keras.constraints import max_norm \n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "from tensorflow.keras.utils import set_random_seed\n",
        "set_random_seed(3)\n",
        "import matplotlib.pyplot as plt                                                 \n",
        "from scipy import interpolate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parameters Declaration \n",
        "Lenght of Message space, Number of bits per symbol, number of channel uses\n",
        "and Rate of communication is defined here. "
      ],
      "metadata": {
        "id": "2zTzktIN_LAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "L_o_m  = 4                                                                      # Lenght of Message space(M) given by 2^number of bits \n",
        "bits = np.log2(L_o_m)                                                           # Number of bits \n",
        "bits = int(bits)                                                                # Converting it to int \n",
        "n = 2                                                                           # Number of channels(n) \n",
        "R = bits/n                                                                      # Communication rate(R) given by number of bits divided by number of channels \n",
        "print ('Lenght of Message space (M):',L_o_m,'Number of bits (k):',bits,'Number of channels (n):',n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqlokJnxa0P-",
        "outputId": "37510f8c-1ddb-495b-9302-9595cee2fd1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lenght of Message space (M): 4 Number of bits (k): 2 Number of channels (n): 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating training data"
      ],
      "metadata": {
        "id": "rHe_SSueADk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "samples = 100000\n",
        "labels = np.random.randint(L_o_m , size=samples)                                # generating N random numbers whose values are enclosed between 0 and (M-1)"
      ],
      "metadata": {
        "id": "01xhM5MWa4Jl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performing Onehot Encoding\n",
        "Each of the message in generated message space is onehot encoded. "
      ],
      "metadata": {
        "id": "TJPJNPzJAko9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = []                                                              # Creating a empty list \n",
        "for i in labels:                         \n",
        "    inp_vector = np.zeros(L_o_m)                                                # Creating a numpy array of size M                                                    \n",
        "    inp_vector[i] = 1                                                           # Performing one hot encoding \n",
        "    training_data.append(inp_vector) \n",
        "\n"
      ],
      "metadata": {
        "id": "fZA-OwDvboBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = np.array(training_data)                                         # Transforming data to numpy array\n",
        "print (training_data.shape)                                                     # Each of the sample out of the N generated samples is onehot encoded to vector of size M "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ppnpj4ubrsF",
        "outputId": "e59e765c-b045-4468-8a51-6b1a59b465ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100000, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verifying the one hot encoding performed on the generated data.  \n"
      ],
      "metadata": {
        "id": "diWa01MlD-ic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "check_list = [23,45,97,115,278,369]\n",
        "for i in check_list:\n",
        "    print(labels[i],training_data[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwwdatTObvhc",
        "outputId": "f44fb984-1e1a-452b-fa3e-3be11b29487c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 [0. 0. 1. 0.]\n",
            "3 [0. 0. 0. 1.]\n",
            "0 [1. 0. 0. 0.]\n",
            "0 [1. 0. 0. 0.]\n",
            "2 [0. 0. 1. 0.]\n",
            "3 [0. 0. 0. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining the architecture of Autoencoder"
      ],
      "metadata": {
        "id": "H2uQEQoIFBWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_signal = Input(shape=(L_o_m,))                                            # After performing one hot encoding each input is vector of size M\n",
        "encoded1 = Dense(L_o_m, activation='relu')(input_signal)                         # First layer is dense layer with relu activation function and M nuerons  \n",
        "encoded2 = Dense(n, activation='linear')(encoded1)                               # Second layer is dense layer with linear activaton function and n_channel nuerons \n",
        "#encoded3 = Lambda(lambda x: np.sqrt(n)*K.l2_normalize(x,axis=1))(encoded2)      # Normalisation is performed to met the physical constraints (Energy Constraint)\n",
        "encoded3 = BatchNormalization(gamma_constraint=max_norm(1.4142136))(encoded2) \n",
        "\n",
        "\n",
        "EbNo_train = 5.01187                                                            # coverted 7 db of EbNo\n",
        "                                                                                # 10log(EbNo) = 7 db\n",
        "encoded4 = GaussianNoise(np.sqrt(1/(2*R*EbNo_train)))(encoded3)                 # As Variance is given by (1/(2*R*EbNo_train) \n",
        "                                                                                # Gausian noise is added by this layer \n",
        "\n",
        "decoded1 = Dense(L_o_m, activation='relu')(encoded4)                             # First layer of the decoder is dense layer with relu activation function and total M nuerons\n",
        "decoded2 = Dense(L_o_m, activation='softmax')(decoded1)                          # Second layer of the decoder is dense layer with softmax activation function which outputs the probabilities \n",
        "\n",
        "\n",
        "autoencoder = Model(input_signal, decoded2)                                     # Autoencoder model is defined here \n",
        "adam = Adam(learning_rate=0.001)                                                # Adam optimizer is used with learning rate 0.01 to minimise the loss \n",
        "\n",
        "autoencoder.compile(optimizer=adam, loss='categorical_crossentropy')            # Autoencoder is compiled here and loss is defined as categorical crossentropy between the onehot encoded input vector and the output of the decoder "
      ],
      "metadata": {
        "id": "-FNphna1bxfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary of Autoencoder"
      ],
      "metadata": {
        "id": "7xS2b5trFX2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (autoencoder.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4o2A_DywcfK1",
        "outputId": "9cd78dc2-e487-42cf-cc83-8139e1cd2be3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 4)]               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4)                 20        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 10        \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 2)                8         \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " gaussian_noise (GaussianNoi  (None, 2)                0         \n",
            " se)                                                             \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 4)                 12        \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 4)                 20        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 70\n",
            "Trainable params: 66\n",
            "Non-trainable params: 4\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model "
      ],
      "metadata": {
        "id": "KsIqAPGUFjdr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.fit(training_data, training_data, epochs=150, batch_size=64)        # Autoencoder is fitted with the generated data                                         "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zk1GFPac4-M",
        "outputId": "548fa73b-fa8e-4895-b356-eab9dfd2a5fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "1563/1563 [==============================] - 9s 4ms/step - loss: 0.3973\n",
            "Epoch 2/150\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0380\n",
            "Epoch 3/150\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0199\n",
            "Epoch 4/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0152\n",
            "Epoch 5/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0142\n",
            "Epoch 6/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0133\n",
            "Epoch 7/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0125\n",
            "Epoch 8/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0122\n",
            "Epoch 9/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0116\n",
            "Epoch 10/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0118\n",
            "Epoch 11/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0110\n",
            "Epoch 12/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0111\n",
            "Epoch 13/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0113\n",
            "Epoch 14/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0116\n",
            "Epoch 15/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0117\n",
            "Epoch 16/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0110\n",
            "Epoch 17/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0106\n",
            "Epoch 18/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0104\n",
            "Epoch 19/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0104\n",
            "Epoch 20/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0110\n",
            "Epoch 21/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0107\n",
            "Epoch 22/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0107\n",
            "Epoch 23/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0101\n",
            "Epoch 24/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0102\n",
            "Epoch 25/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0104\n",
            "Epoch 26/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0103\n",
            "Epoch 27/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0105\n",
            "Epoch 28/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0107\n",
            "Epoch 29/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0104\n",
            "Epoch 30/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0096\n",
            "Epoch 31/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0098\n",
            "Epoch 32/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0097\n",
            "Epoch 33/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0109\n",
            "Epoch 34/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0098\n",
            "Epoch 35/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0108\n",
            "Epoch 36/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0099\n",
            "Epoch 37/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0106\n",
            "Epoch 38/150\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0098\n",
            "Epoch 39/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0097\n",
            "Epoch 40/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0094\n",
            "Epoch 41/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0111\n",
            "Epoch 42/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0086\n",
            "Epoch 43/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0092\n",
            "Epoch 44/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0091\n",
            "Epoch 45/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0090\n",
            "Epoch 46/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0110\n",
            "Epoch 47/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0104\n",
            "Epoch 48/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0114\n",
            "Epoch 49/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0101\n",
            "Epoch 50/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0099\n",
            "Epoch 51/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0105\n",
            "Epoch 52/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0099\n",
            "Epoch 53/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0089\n",
            "Epoch 54/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0100\n",
            "Epoch 55/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0095\n",
            "Epoch 56/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0098\n",
            "Epoch 57/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0100\n",
            "Epoch 58/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0101\n",
            "Epoch 59/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0103\n",
            "Epoch 60/150\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.0100\n",
            "Epoch 61/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0103\n",
            "Epoch 62/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0097\n",
            "Epoch 63/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0100\n",
            "Epoch 64/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0106\n",
            "Epoch 65/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0095\n",
            "Epoch 66/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0096\n",
            "Epoch 67/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0097\n",
            "Epoch 68/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0102\n",
            "Epoch 69/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0097\n",
            "Epoch 70/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0100\n",
            "Epoch 71/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0095\n",
            "Epoch 72/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0093\n",
            "Epoch 73/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0093\n",
            "Epoch 74/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0098\n",
            "Epoch 75/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0085\n",
            "Epoch 76/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0106\n",
            "Epoch 77/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0090\n",
            "Epoch 78/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0100\n",
            "Epoch 79/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0098\n",
            "Epoch 80/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0102\n",
            "Epoch 81/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0092\n",
            "Epoch 82/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0094\n",
            "Epoch 83/150\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.0102\n",
            "Epoch 84/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0100\n",
            "Epoch 85/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0104\n",
            "Epoch 86/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0093\n",
            "Epoch 87/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0090\n",
            "Epoch 88/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0109\n",
            "Epoch 89/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0096\n",
            "Epoch 90/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0096\n",
            "Epoch 91/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0098\n",
            "Epoch 92/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0096\n",
            "Epoch 93/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0100\n",
            "Epoch 94/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0098\n",
            "Epoch 95/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0090\n",
            "Epoch 96/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0092\n",
            "Epoch 97/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0092\n",
            "Epoch 98/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0100\n",
            "Epoch 99/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0094\n",
            "Epoch 100/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0100\n",
            "Epoch 101/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0094\n",
            "Epoch 102/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0096\n",
            "Epoch 103/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0095\n",
            "Epoch 104/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0098\n",
            "Epoch 105/150\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.0101\n",
            "Epoch 106/150\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.0106\n",
            "Epoch 107/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0099\n",
            "Epoch 108/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0094\n",
            "Epoch 109/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0094\n",
            "Epoch 110/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0098\n",
            "Epoch 111/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0102\n",
            "Epoch 112/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0094\n",
            "Epoch 113/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0093\n",
            "Epoch 114/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0096\n",
            "Epoch 115/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0101\n",
            "Epoch 116/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0103\n",
            "Epoch 117/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0095\n",
            "Epoch 118/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0092\n",
            "Epoch 119/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0096\n",
            "Epoch 120/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0094\n",
            "Epoch 121/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0099\n",
            "Epoch 122/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0095\n",
            "Epoch 123/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0095\n",
            "Epoch 124/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0103\n",
            "Epoch 125/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0099\n",
            "Epoch 126/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0092\n",
            "Epoch 127/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0092\n",
            "Epoch 128/150\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.0097\n",
            "Epoch 129/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0095\n",
            "Epoch 130/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0093\n",
            "Epoch 131/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0094\n",
            "Epoch 132/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0093\n",
            "Epoch 133/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0103\n",
            "Epoch 134/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0102\n",
            "Epoch 135/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0099\n",
            "Epoch 136/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0092\n",
            "Epoch 137/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0096\n",
            "Epoch 138/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0094\n",
            "Epoch 139/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0094\n",
            "Epoch 140/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0100\n",
            "Epoch 141/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0094\n",
            "Epoch 142/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0096\n",
            "Epoch 143/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0095\n",
            "Epoch 144/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0097\n",
            "Epoch 145/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0097\n",
            "Epoch 146/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0093\n",
            "Epoch 147/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0088\n",
            "Epoch 148/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0106\n",
            "Epoch 149/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0097\n",
            "Epoch 150/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0095\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f07381672d0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoder"
      ],
      "metadata": {
        "id": "CBhIz2mNJHZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Model(input_signal, encoded3)                                         # Model of Encoder is Defined here  "
      ],
      "metadata": {
        "id": "BYWkzH-JdD-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decoder "
      ],
      "metadata": {
        "id": "quDydVnmJMJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_input = Input(shape=(n,))                                               # Model for decoder is defined here  \n",
        "\n",
        "decoder_1 = autoencoder.layers[-2](encoded_input)                               # Second last layer of the defined Autoencoder \n",
        "decoder_2 = autoencoder.layers[-1](decoder_1)                                   # Last layer of the defined Autoencoder \n",
        "decoder = Model(encoded_input, decoder_2)                                 "
      ],
      "metadata": {
        "id": "AtTTid3VdHRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating Test data "
      ],
      "metadata": {
        "id": "1zr1VftzNtaw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_samples = 10000                                                            # Size of test samples \n",
        "                                                                                # t-distributed stochastic neighbor embedding (t-SNE) is a statistical method for visualizing high-dimensional data\n",
        "                                                                                # by giving each datapoint a location in a two or three-dimensional map\n",
        "test_labels = np.random.randint(L_o_m,size=test_samples)                        # Test data of size N is created with all values enclosed between 0 and M\n",
        "test_data = []\n",
        "\n",
        "for i in test_labels:\n",
        "    test_vector = np.zeros(L_o_m)                                               # Numpy array of size M is created with all entries equal to zero \n",
        "    test_vector[i] = 1                                                          # performing One hot encoding on each entry of N \n",
        "    test_data.append(test_vector)\n",
        "    \n",
        "test_data = np.array(test_data)                                                 # Test data is converted to numpy array \n",
        "print(test_data.shape)                                                          # Shape of test_data is given by (N*M)"
      ],
      "metadata": {
        "id": "1sMlQgCUdLvr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c32feaef-1f70-4ddc-b3b3-d8dba10bbdf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_num = 99                                                                   # Verifying the onehot encoding on generated test data \n",
        "print (test_data[test_num],test_labels[test_num])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pm9hoWPPdNVT",
        "outputId": "3f8627cd-6e80-42c0-9783-ba8e71298b81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 0. 1.] 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Constellation Diagram\n",
        "Every message in the message space is encode to draw constellation diagram "
      ],
      "metadata": {
        "id": "1CulcMPYOglR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scatter_plot = []                                                                \n",
        "for i in range(0,L_o_m):                                                        # For all the messages in the message space \n",
        "    array1 = np.zeros(L_o_m)\n",
        "    \n",
        "    array1[i] = 1                                                               # onehot encoding of the each message\n",
        "    scatter_plot.append(encoder.predict(np.expand_dims(array1,axis=0)))         # Encoding every possible entry of Messages needed to be sent \n",
        "scatter_plot = np.array(scatter_plot)                                           # As you can see for each of the sixteen possible values there is a complex representation \n",
        "print (scatter_plot.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5O_d2o9dV-s",
        "outputId": "27452077-524e-4011-f556-8f492e7df8bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 1, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scatter_plot = scatter_plot.reshape(L_o_m,2,1)                                  # Constellation diagram\n",
        "plt.scatter(scatter_plot[:,0],scatter_plot[:,1] )                               # quadrature phase shift keying (QPSK) for (2,2)\n",
        "plt.axis((-2.5,3.5,-2.5,2.5))                                                   # Rotated 16 PSK constellation for (2,4)\n",
        "\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "eUplxgHfdoFz",
        "outputId": "79b7147d-dffd-4bb1-aaec-e974aa9eab75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculating Bit Error Rate "
      ],
      "metadata": {
        "id": "ztU93yDPO2Lx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def frange(i, j, jump):                                                         # For represnting SNR after overy 0.5 db interval \n",
        "  while i < j:\n",
        "    yield i\n",
        "    i += jump"
      ],
      "metadata": {
        "id": "jjRI-2yKdrNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SNR_range = list(frange(-4,12,0.5))                                             # Range of SNR \n",
        "print(len(SNR_range))                                                           # In total there are 25 intervals\n",
        "  \n",
        "BER = [None]*len(SNR_range)                                                  \n",
        "                                                 \n",
        "for x in range(0,len(SNR_range)):                                               # for each of the value of SNR \n",
        "    EbNo=10.0**(SNR_range[x]/10.0)                                              # to covert each value of SNR from db's\n",
        "    noise_std = np.sqrt(1/(2*R*EbNo))                                           # Standard deviation of the added noise layer \n",
        "    mean = 0                                                                    # Mean of the added noise layer \n",
        "    errors = 0\n",
        "    \n",
        "    noise = noise_std * np.random.randn(test_samples,n)                         # Noise is added to encoded data\n",
        "    encoded_vector = encoder.predict(test_data)                                 # Encoded test data \n",
        "    noise_added_vector = encoded_vector + noise                                 # Encoded test data + Noise\n",
        "\n",
        "    decoded_vector =  decoder.predict(noise_added_vector)                       # Decoded data \n",
        "    pred_output = np.argmax(decoded_vector,axis=1)                              # As the decoder last layer is Softmax so the index with the highest probabilty is chosen\n",
        "    errors = (pred_output != test_labels)                                       # It checks for each of the test_sample is the predicted value is same as the original value \n",
        "    \n",
        "    errors =  errors.astype(int).sum()                                          # Adds up the total Error bits in each of the iteration for N values  \n",
        "        \n",
        "    BER[x] = errors / test_samples                                              # BER is given by total  wrongly identified examples over total number of Examples\n",
        "\n",
        "    print ('SNR (Signal to noise ratio):',SNR_range[x],'BER (Bit Error Rate):',BER[x])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CICwsaTdx5c",
        "outputId": "d999eda7-e0d5-4e66-82e8-365494382bfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32\n",
            "SNR (Signal to noise ratio): -4 BER (Bit Error Rate): 0.3331\n",
            "SNR (Signal to noise ratio): -3.5 BER (Bit Error Rate): 0.309\n",
            "SNR (Signal to noise ratio): -3.0 BER (Bit Error Rate): 0.2819\n",
            "SNR (Signal to noise ratio): -2.5 BER (Bit Error Rate): 0.2557\n",
            "SNR (Signal to noise ratio): -2.0 BER (Bit Error Rate): 0.2374\n",
            "SNR (Signal to noise ratio): -1.5 BER (Bit Error Rate): 0.2122\n",
            "SNR (Signal to noise ratio): -1.0 BER (Bit Error Rate): 0.2\n",
            "SNR (Signal to noise ratio): -0.5 BER (Bit Error Rate): 0.1725\n",
            "SNR (Signal to noise ratio): 0.0 BER (Bit Error Rate): 0.1465\n",
            "SNR (Signal to noise ratio): 0.5 BER (Bit Error Rate): 0.1324\n",
            "SNR (Signal to noise ratio): 1.0 BER (Bit Error Rate): 0.1005\n",
            "SNR (Signal to noise ratio): 1.5 BER (Bit Error Rate): 0.0855\n",
            "SNR (Signal to noise ratio): 2.0 BER (Bit Error Rate): 0.069\n",
            "SNR (Signal to noise ratio): 2.5 BER (Bit Error Rate): 0.0574\n",
            "SNR (Signal to noise ratio): 3.0 BER (Bit Error Rate): 0.042\n",
            "SNR (Signal to noise ratio): 3.5 BER (Bit Error Rate): 0.0308\n",
            "SNR (Signal to noise ratio): 4.0 BER (Bit Error Rate): 0.0242\n",
            "SNR (Signal to noise ratio): 4.5 BER (Bit Error Rate): 0.0163\n",
            "SNR (Signal to noise ratio): 5.0 BER (Bit Error Rate): 0.0112\n",
            "SNR (Signal to noise ratio): 5.5 BER (Bit Error Rate): 0.0086\n",
            "SNR (Signal to noise ratio): 6.0 BER (Bit Error Rate): 0.0044\n",
            "SNR (Signal to noise ratio): 6.5 BER (Bit Error Rate): 0.0021\n",
            "SNR (Signal to noise ratio): 7.0 BER (Bit Error Rate): 0.0015\n",
            "SNR (Signal to noise ratio): 7.5 BER (Bit Error Rate): 0.0006\n",
            "SNR (Signal to noise ratio): 8.0 BER (Bit Error Rate): 0.0007\n",
            "SNR (Signal to noise ratio): 8.5 BER (Bit Error Rate): 0.0003\n",
            "SNR (Signal to noise ratio): 9.0 BER (Bit Error Rate): 0.0\n",
            "SNR (Signal to noise ratio): 9.5 BER (Bit Error Rate): 0.0\n",
            "SNR (Signal to noise ratio): 10.0 BER (Bit Error Rate): 0.0\n",
            "SNR (Signal to noise ratio): 10.5 BER (Bit Error Rate): 0.0\n",
            "SNR (Signal to noise ratio): 11.0 BER (Bit Error Rate): 0.0\n",
            "SNR (Signal to noise ratio): 11.5 BER (Bit Error Rate): 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot of Bit Error Rate against Range of SNR"
      ],
      "metadata": {
        "id": "4DWbspcUp439"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.plot(SNR_range, BER, 'bo',label='Autoencoder(2,2)')\n",
        "plt.yscale('log')\n",
        "plt.xlabel('SNR Range')\n",
        "plt.ylabel('Block Error Rate')\n",
        "plt.grid()\n",
        "plt.legend(loc='upper right',ncol = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "GrswTvJod9Xs",
        "outputId": "39041514-0b97-47f2-eed8-53dc286c1e70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f0732a747d0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}